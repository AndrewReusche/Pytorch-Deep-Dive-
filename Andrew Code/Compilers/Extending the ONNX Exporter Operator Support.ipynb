{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4528b1-5443-47bc-b367-a16231b42ab9",
   "metadata": {},
   "source": [
    "# Extending the ONNX Exporter Operator Support\n",
    "\n",
    "## Overview\n",
    "This tutorial describes how you can create ONNX implementation for unsupported PyTorch operators or replace existing implementation with your own.\n",
    "\n",
    "We will cover three scenarios that require extending the ONNX exporter’s operator support:\n",
    "\n",
    "Overriding the implementation of an existing PyTorch operator\n",
    "\n",
    "Using custom ONNX operators\n",
    "\n",
    "Supporting a custom PyTorch operator\n",
    "\n",
    "What you will learn:\n",
    "\n",
    "How to override or add support for PyTorch operators in ONNX.\n",
    "\n",
    "How to integrate custom ONNX operators for specialized runtimes.\n",
    "\n",
    "How to implement and translate custom PyTorch operators to ONNX.\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this tutorial, make sure you have completed the following prerequisites:\n",
    "\n",
    "torch >= 2.6\n",
    "\n",
    "The target PyTorch operator\n",
    "\n",
    "Completed the ONNX Script tutorial before proceeding\n",
    "\n",
    "The implementation of the operator using ONNX Script\n",
    "\n",
    "## Overriding the implementation of an existing PyTorch operator\n",
    "Although the ONNX exporter team does their best efforts to support all PyTorch operators, some of them might not be supported yet. In this section, we will demonstrate how you can add unsupported PyTorch operators to the ONNX Registry.\n",
    "\n",
    "Note\n",
    "\n",
    "The steps to implement unsupported PyTorch operators are the same as those for replacing the implementation of an existing PyTorch operator with a custom one. Because we don’t actually have an unsupported PyTorch operator to use in this tutorial, we are going to leverage this and replace the implementation of torch.ops.aten.add.Tensor with a custom implementation the same way we would if the operator was not implemented by the ONNX exporter.\n",
    "\n",
    "When a model cannot be exported to ONNX due to an unsupported operator, the ONNX exporter will show an error message similar to:\n",
    "\n",
    "    \"No decompositions registered for [...]\"\n",
    "\n",
    "The error message indicates that the unsupported PyTorch operator is torch.ops.aten.add.Tensor. The operator is of type <class 'torch._ops.OpOverload'>, and this operator is what we will use as the target to register our custom implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f67a2a-9165-4b0c-a76a-115bd6db27b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 18:16:15.714000 67163 site-packages/torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'self' from (self, other, alpha: float = 1.0). Treating as an Input.\n",
      "W1014 18:16:15.715000 67163 site-packages/torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'other' from (self, other, alpha: float = 1.0). Treating as an Input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `Model()` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `Model()` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnxscript\n",
    "\n",
    "# Opset 18 is the standard supported version as of PyTorch 2.6\n",
    "from onnxscript import opset18 as op\n",
    "\n",
    "\n",
    "# Create a model that uses the operator torch.ops.aten.add.Tensor\n",
    "class Model(torch.nn.Module):\n",
    "    def forward(self, input_x, input_y):\n",
    "        return torch.ops.aten.add.Tensor(input_x, input_y)\n",
    "\n",
    "\n",
    "# NOTE: The function signature (including parameter names) must match the signature of the unsupported PyTorch operator.\n",
    "# https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml\n",
    "# All attributes must be annotated with type hints.\n",
    "def custom_aten_add(self, other, alpha: float = 1.0):\n",
    "    if alpha != 1.0:\n",
    "        alpha = op.CastLike(alpha, other)\n",
    "        other = op.Mul(other, alpha)\n",
    "    # To distinguish the custom implementation from the built-in one, we switch the order of the inputs\n",
    "    return op.Add(other, self)\n",
    "\n",
    "\n",
    "x = torch.tensor([1.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "# Then we provide the custom implementation to the ONNX exporter as a ``custom_translation_table``.\n",
    "onnx_program = torch.onnx.export(\n",
    "    Model().eval(),\n",
    "    (x, y),\n",
    "    dynamo=True,\n",
    "    custom_translation_table={\n",
    "        torch.ops.aten.add.Tensor: custom_aten_add,\n",
    "    },\n",
    ")\n",
    "# Optimize the ONNX graph to remove redundant nodes\n",
    "onnx_program.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6c6d4-2910-45d2-981f-0d78cf4525aa",
   "metadata": {},
   "source": [
    "Now let’s inspect the model and verify the model is using the custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cef88c-bd38-4281-b00a-23c51889bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'': 18},\n",
      "    producer_name='pytorch',\n",
      "    producer_version='2.8.0',\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input_x\"<FLOAT,[1]>,\n",
      "        %\"input_y\"<FLOAT,[1]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"add\"<FLOAT,[1]>\n",
      "    ),\n",
      ") {\n",
      "    0 |  # node_add\n",
      "         %\"add\"<FLOAT,[1]> ⬅️ ::Add(%\"input_y\", %\"input_x\")\n",
      "    return %\"add\"<FLOAT,[1]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(onnx_program.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7144d-1722-49d1-a4a5-9b0401eb9140",
   "metadata": {},
   "source": [
    "The translation is using our custom implementation: In node node_Add_0, input_y now comes first, and input_x comes second.\n",
    "\n",
    "We can use ONNX Runtime to run the model and verify the results by calling the torch.onnx.ONNXProgram directly on the input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62e49cc-467f-445c-a83f-8f674906a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = onnx_program(x, y)[0]\n",
    "torch.testing.assert_close(result, torch.tensor([3.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717961dd-33a8-4e9f-bc0e-4eb577083da1",
   "metadata": {},
   "source": [
    "## Using custom ONNX operators\n",
    "In this case, we create a model with standard PyTorch operators, but the runtime (such as Microsoft’s ONNX Runtime) can provide a custom implementation for that kernel, effectively replacing the existing implementation.\n",
    "\n",
    "In the following example, we use the com.microsoft.Gelu operator provided by ONNX Runtime, which is not the same Gelu from ONNX spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8368ce-6dee-43e4-9b21-c837ac96d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `GeluModel()` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `GeluModel()` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "class GeluModel(torch.nn.Module):\n",
    "    def forward(self, input_x):\n",
    "        return torch.ops.aten.gelu(input_x)\n",
    "\n",
    "\n",
    "# Create a namespace for the custom operator using ONNX Script\n",
    "# ``com.microsoft`` is an official ONNX Runtime namespace\n",
    "microsoft_op = onnxscript.values.Opset(domain=\"com.microsoft\", version=1)\n",
    "\n",
    "# NOTE: The function signature (including parameter names) must match the signature of the unsupported PyTorch operator.\n",
    "# https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml\n",
    "# NOTE: All attributes must be annotated with type hints.\n",
    "# The function must be scripted using the ``@onnxscript.script()`` decorator when\n",
    "# using operators from custom domains. This may be improved in future versions.\n",
    "from onnxscript import FLOAT\n",
    "\n",
    "\n",
    "@onnxscript.script(microsoft_op)\n",
    "def custom_aten_gelu(self: FLOAT, approximate: str = \"none\") -> FLOAT:\n",
    "    return microsoft_op.Gelu(self)\n",
    "\n",
    "\n",
    "onnx_program = torch.onnx.export(\n",
    "    GeluModel().eval(),\n",
    "    (x,),\n",
    "    dynamo=True,\n",
    "    custom_translation_table={\n",
    "        torch.ops.aten.gelu.default: custom_aten_gelu,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Optimize the ONNX graph to remove redundant nodes\n",
    "onnx_program.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8195d36-1798-4a18-abe3-6074a5fac746",
   "metadata": {},
   "source": [
    "Let’s inspect the model and verify the model uses op_type Gelu from namespace com.microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096657cf-ba77-4296-b42f-7f9520032a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      "    ir_version=10,\n",
      "    opset_imports={'com.microsoft': 1, '': 18},\n",
      "    producer_name='pytorch',\n",
      "    producer_version='2.8.0',\n",
      "    domain=None,\n",
      "    model_version=None,\n",
      ">\n",
      "graph(\n",
      "    name=main_graph,\n",
      "    inputs=(\n",
      "        %\"input_x\"<FLOAT,[1]>\n",
      "    ),\n",
      "    outputs=(\n",
      "        %\"gelu\"<FLOAT,[1]>\n",
      "    ),\n",
      ") {\n",
      "    0 |  # n0\n",
      "         %\"gelu\"<FLOAT,[1]> ⬅️ com.microsoft::Gelu(%\"input_x\")\n",
      "    return %\"gelu\"<FLOAT,[1]>\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(onnx_program.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229a877-baca-4a7b-9705-2ae2b85b71e6",
   "metadata": {},
   "source": [
    "Similar to the previous example, we can use ONNX Runtime to run the model and verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ef9b67-53d7-41eb-ba6b-84067226fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = onnx_program(x)[0]\n",
    "torch.testing.assert_close(result, torch.ops.aten.gelu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195eaf3b-6e05-40bf-a1db-adb78ce787cf",
   "metadata": {},
   "source": [
    "## Supporting a custom PyTorch operator\n",
    "In this case, the operator is an operator that is user implemented and registered to PyTorch.\n",
    "\n",
    "In the following example, we would like to use a custom operator that takes one tensor input, and returns one output. The operator adds the input to itself, and returns the rounded result.\n",
    "\n",
    "Firstly, we assume the custom operator is implemented and registered with torch.library.custom_op(). You can refer to Creating new custom ops in Python for a detailed guide on how to create custom operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f939c45-ae87-440a-95af-4228f0014a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 20:06:25.761000 67163 site-packages/torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'input' from (input). Treating as an Input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `AddAndRoundModel()` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `AddAndRoundModel()` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "ONNXProgram(\n",
      "    model=\n",
      "        <\n",
      "            ir_version=10,\n",
      "            opset_imports={'': 18},\n",
      "            producer_name='pytorch',\n",
      "            producer_version='2.8.0',\n",
      "            domain=None,\n",
      "            model_version=None,\n",
      "        >\n",
      "        graph(\n",
      "            name=main_graph,\n",
      "            inputs=(\n",
      "                %\"input\"<FLOAT,[1]>\n",
      "            ),\n",
      "            outputs=(\n",
      "                %\"add_and_round_op\"<FLOAT,[1]>\n",
      "            ),\n",
      "        ) {\n",
      "            0 |  # node_Add_0\n",
      "                 %\"val_0\"<FLOAT,[1]> ⬅️ ::Add(%\"input\", %\"input\")\n",
      "            1 |  # node_add_and_round_op\n",
      "                 %\"add_and_round_op\"<FLOAT,[1]> ⬅️ ::Round(%\"val_0\")\n",
      "            return %\"add_and_round_op\"<FLOAT,[1]>\n",
      "        }\n",
      "\n",
      "\n",
      "    ,\n",
      "    exported_program=\n",
      "        ExportedProgram:\n",
      "            class GraphModule(torch.nn.Module):\n",
      "                def forward(self, input: \"f32[1]\"):\n",
      "                    input_1 = input\n",
      "            \n",
      "                     # File: /var/folders/p_/7g5qyc8d5zv5nfywm65yhpkc0000gn/T/ipykernel_67163/4090856442.py:14 in forward, code: return add_and_round_op(input)\n",
      "                    add_and_round_op: \"f32[1]\" = torch.ops.mylibrary.add_and_round_op.default(input_1);  input_1 = None\n",
      "                    return (add_and_round_op,)\n",
      "            \n",
      "        Graph signature: \n",
      "            # inputs\n",
      "            input: USER_INPUT\n",
      "    \n",
      "            # outputs\n",
      "            add_and_round_op: USER_OUTPUT\n",
      "    \n",
      "        Range constraints: {}\n",
      "\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define and use the operator in PyTorch\n",
    "@torch.library.custom_op(\"mylibrary::add_and_round_op\", mutates_args=())\n",
    "def add_and_round_op(input: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.round(input + input)\n",
    "\n",
    "\n",
    "@add_and_round_op.register_fake\n",
    "def _add_and_round_op_fake(tensor_x):\n",
    "    return torch.empty_like(tensor_x)\n",
    "\n",
    "\n",
    "class AddAndRoundModel(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return add_and_round_op(input)\n",
    "\n",
    "\n",
    "# Implement the custom operator in ONNX using ONNX Script\n",
    "def onnx_add_and_round(input):\n",
    "    return op.Round(op.Add(input, input))\n",
    "\n",
    "\n",
    "onnx_program = torch.onnx.export(\n",
    "    AddAndRoundModel().eval(),\n",
    "    (x,),\n",
    "    dynamo=True,\n",
    "    custom_translation_table={\n",
    "        torch.ops.mylibrary.add_and_round_op.default: onnx_add_and_round,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Optimize the ONNX graph to remove redundant nodes\n",
    "onnx_program.optimize()\n",
    "print(onnx_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e097e-73a7-4707-b0d0-ddb1f55645a3",
   "metadata": {},
   "source": [
    "The translation is using our custom implementation to translate the torch.ops.mylibrary.add_and_round_op.default operator in the torch.export.ExportedProgram` to the ONNX operator Add and Round.\n",
    "\n",
    "Finally we verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5701008-d9af-4758-94c7-577f8a8a094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = onnx_program(x)[0]\n",
    "torch.testing.assert_close(result, add_and_round_op(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e57e5-ee24-4672-9941-6df17415750f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations! In this tutorial, we explored the custom_translation_table option and discovered how to create custom implementations for unsupported or existing PyTorch operators using ONNX Script.\n",
    "\n",
    "Finally, we leveraged ONNX Runtime to execute the model and compare the results with PyTorch, providing us with a comprehensive understanding of handling unsupported operators in the ONNX ecosystem.\n",
    "\n",
    "## Further reading\n",
    "The list below refers to tutorials that ranges from basic examples to advanced scenarios, not necessarily in the order they are listed. Feel free to jump directly to specific topics of your interest or sit tight and have fun going through all of them to learn all there is about the ONNX exporter.\n",
    "\n",
    "1. Exporting a PyTorch model to ONNX\n",
    "2. Extending the ONNX exporter operator support\n",
    "3. Export a model with control flow to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58d6b1-e73b-4145-8212-208663ffc2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
