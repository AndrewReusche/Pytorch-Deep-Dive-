{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db6c128-8d8b-4c0e-9c2a-a44f80359f2e",
   "metadata": {},
   "source": [
    "# Introduction to ONNX\n",
    "\n",
    "Open Neural Network eXchange (ONNX) is an open standard format for representing machine learning models. The torch.onnx module provides APIs to capture the computation graph from a native PyTorch torch.nn.Module model and convert it into an ONNX graph.\n",
    "\n",
    "The exported model can be consumed by any of the many runtimes that support ONNX, including Microsoft’s ONNX Runtime.\n",
    "\n",
    "When setting dynamo=True, the exporter will use torch.export to capture an ExportedProgram, before translating the graph into ONNX representations. This approach is the new and recommended way to export models to ONNX. It works with PyTorch 2.0 features more robustly, has better support for newer ONNX operator sets, and consumes less resources to make exporting larger models possible.\n",
    "\n",
    "## Dependencies\n",
    "PyTorch 2.5.0 or newer is required.\n",
    "\n",
    "The ONNX exporter depends on extra Python packages:\n",
    "\n",
    "ONNX standard library\n",
    "\n",
    "ONNX Script library that enables developers to author ONNX operators, functions and models using a subset of Python in an expressive, and yet simple fashion\n",
    "\n",
    "ONNX Runtime accelerated machine learning library.\n",
    "\n",
    "They can be installed through pip:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce44587d-8e32-496b-be09-b5b4a31a8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.19.1-cp312-cp312-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "Collecting onnxscript\n",
      "  Downloading onnxscript-0.5.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.23.1-cp312-cp312-macosx_13_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from onnx) (2.3.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from onnx) (4.15.0)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting onnx_ir<2,>=0.1.10 (from onnxscript)\n",
      "  Downloading onnx_ir-0.1.10-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from onnxscript) (25.0)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from onnxruntime) (1.14.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnx-1.19.1-cp312-cp312-macosx_12_0_universal2.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading onnxscript-0.5.3-py3-none-any.whl (679 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.0/680.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading onnx_ir-0.1.10-py3-none-any.whl (127 kB)\n",
      "Downloading onnxruntime-1.23.1-cp312-cp312-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, ml_dtypes, humanfriendly, onnx, coloredlogs, onnxruntime, onnx_ir, onnxscript\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [onnxscript]8\u001b[0m [onnxscript]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 ml_dtypes-0.5.3 onnx-1.19.1 onnx_ir-0.1.10 onnxruntime-1.23.1 onnxscript-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade onnx onnxscript onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51304ae6-0ff0-4507-90e5-a1cc3c95da40",
   "metadata": {},
   "source": [
    "To validate the installation, run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714c6fff-e373-415a-bf74-23446c55078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "0.5.3\n",
      "1.23.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import onnxscript\n",
    "print(onnxscript.__version__)\n",
    "\n",
    "import onnxruntime\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8872b87-138e-49ec-a2fb-cb79b9739a96",
   "metadata": {},
   "source": [
    "# Further reading\n",
    "The list below refers to tutorials that ranges from basic examples to advanced scenarios, not necessarily in the order they are listed. Feel free to jump directly to specific topics of your interest or sit tight and have fun going through all of them to learn all there is about the ONNX exporter.\n",
    "\n",
    "1. Exporting a PyTorch model to ONNX\n",
    "2. Extending the ONNX exporter operator support\n",
    "3. Export a model with control flow to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f3641-f5c4-4906-ac63-254fa0d5fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
